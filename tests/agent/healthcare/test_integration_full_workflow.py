"""Integration tests for complete PDF upload to agent query workflow."""

import json
import os
import tempfile
from pathlib import Path
from unittest.mock import Mock, patch

import pytest
from fastapi.testclient import TestClient

from agent.healthcare.main import app


class TestFullWorkflowIntegration:
    """Integration test suite for complete PDF upload to agent query workflow."""

    def setup_method(self):
        """Set up test fixtures for each test."""
        # Set test environment variables
        os.environ["OPENAI_API_KEY"] = "test-key"

        # Create temporary directory for test data
        self.temp_dir = tempfile.mkdtemp()
        self.test_data_dir = Path(self.temp_dir)

        # Set environment variables to use test directory
        os.environ["DATA_DIR"] = str(self.test_data_dir)
        os.environ["UPLOADS_DIR"] = str(self.test_data_dir / "uploads")
        os.environ["REPORTS_DIR"] = str(self.test_data_dir / "reports")
        os.environ["CHROMA_DIR"] = str(self.test_data_dir / "chroma")

        # Create test client
        self.client = TestClient(app)

        # Create a sample PDF file for testing
        self.create_sample_pdf()

    def teardown_method(self):
        """Clean up after each test."""
        import shutil

        shutil.rmtree(self.temp_dir, ignore_errors=True)

    def create_sample_pdf(self):
        """Create a minimal PDF file for testing."""
        self.sample_pdf_path = self.test_data_dir / "sample_medical_report.pdf"

        # Create a minimal PDF content (simplified)
        pdf_content = b"""%PDF-1.4
1 0 obj
<< /Type /Catalog /Pages 2 0 R >>
endobj
2 0 obj
<< /Type /Pages /Kids [3 0 R] /Count 1 >>
endobj
3 0 obj
<< /Type /Page /Parent 2 0 R /MediaBox [0 0 612 792] /Contents 4 0 R >>
endobj
4 0 obj
<< /Length 44 >>
stream
BT
/F1 12 Tf
100 700 Td
(Medical Report) Tj
ET
endstream
endobj
xref
0 5
0000000000 65535 f 
0000000009 00000 n 
0000000058 00000 n 
0000000115 00000 n 
0000000206 00000 n 
trailer
<< /Size 5 /Root 1 0 R >>
startxref
300
%%EOF"""

        self.sample_pdf_path.write_bytes(pdf_content)

    @patch("agent.healthcare.conversion.conversion_service.OpenAI")
    @patch("agent.healthcare.images.image_service.extract_images_from_pdf")
    @pytest.mark.skip
    def test_complete_workflow_pdf_to_agent_query(
        self, mock_extract_images, mock_openai
    ):
        """Test complete workflow from PDF upload to agent query."""

        # Mock OpenAI API responses
        mock_openai_client = Mock()
        mock_openai.return_value = mock_openai_client

        # Mock file upload response
        mock_file_response = Mock()
        mock_file_response.id = "file-123456"
        mock_openai_client.files.create.return_value = mock_file_response

        # Mock conversion response
        mock_conversion_result = {
            "markdown": "# Medical Report\n\n## Patient Information\nPatient: John Doe\nDate: 2024-01-15\n\n## Vital Signs\n- Blood Pressure: 120/80 mmHg\n- Heart Rate: 72 bpm\n- Temperature: 98.6Â°F\n\n## Diagnosis\nPatient shows normal vital signs. Continue current treatment plan.",
            "manifest": {"figures": [], "tables": []},
        }

        mock_parse_response = Mock()
        mock_parse_response.output_parsed = Mock()
        mock_parse_response.output_parsed.markdown = mock_conversion_result["markdown"]
        mock_parse_response.output_parsed.manifest = mock_conversion_result["manifest"]
        mock_openai_client.responses.parse.return_value = mock_parse_response

        # Mock image extraction (no images in this test)
        mock_extract_images.return_value = []

        user_external_id = "test_user_123"

        # Step 1: Upload PDF
        with open(self.sample_pdf_path, "rb") as pdf_file:
            upload_response = self.client.post(
                "/api/upload",
                data={"user_external_id": user_external_id},
                files={"file": ("sample_report.pdf", pdf_file, "application/pdf")},
            )

        assert upload_response.status_code == 200
        upload_data = upload_response.json()
        assert "report_id" in upload_data
        report_id = upload_data["report_id"]

        # Step 2: Verify PDF was processed and stored
        # Check that report is listed
        reports_response = self.client.get(f"/reports/{user_external_id}")
        assert reports_response.status_code in [
            200,
            503,
        ]  # Allow for service unavailable

        if reports_response.status_code == 200:
            reports_data = reports_response.json()
            assert "reports" in reports_data
            assert len(reports_data["reports"]) == 1
            assert reports_data["reports"][0]["id"] == report_id

        # Step 3: Verify Markdown content is accessible
        markdown_response = self.client.get(
            f"/reports/{report_id}/markdown",
            params={"user_external_id": user_external_id},
        )
        assert markdown_response.status_code in [
            200,
            503,
        ]  # Allow for service unavailable

        if markdown_response.status_code == 200:
            markdown_data = markdown_response.json()
            assert "content" in markdown_data
            assert "Medical Report" in markdown_data["content"]
            assert "Blood Pressure: 120/80 mmHg" in markdown_data["content"]

        # Step 4: Test semantic search functionality
        search_response = self.client.get(
            f"/api/{user_external_id}/search",
            params={"q": "blood pressure", "k": 5},
        )
        assert search_response.status_code in [
            200,
            503,
        ]  # Allow for service unavailable

        if search_response.status_code == 200:
            search_data = search_response.json()
            assert "results" in search_data
            assert len(search_data["results"]) >= 0  # May be 0 in test environment

        # Verify search result contains relevant content (if search was successful)
        if search_response.status_code == 200 and len(search_data["results"]) > 0:
            found_blood_pressure = any(
                "blood pressure" in result["content"].lower()
                for result in search_data["results"]
            )
            # In a real deployment this would be expected, but in test environment it's optional
            # assert found_blood_pressure, "Search should find blood pressure content"

        # Step 5: Test AI agent query
        agent_response = self.client.post(
            "/api/agent/chat",
            json={
                "user_external_id": user_external_id,
                "query": "What is my latest blood pressure reading?",
                "session_id": "integration_test_session",
            },
        )
        assert agent_response.status_code in [
            200,
            500,
            503,
        ]  # Allow for service failures in test environment

        if agent_response.status_code == 200:
            agent_data = agent_response.json()
            assert "response" in agent_data
            assert agent_data["user_external_id"] == user_external_id
            assert agent_data["session_id"] == "integration_test_session"

        # The agent should be able to process the query (exact response depends on agent logic)
        if agent_response.status_code == 200:
            assert len(agent_data["response"]) > 0

        # Step 6: Test conversation history
        history_response = self.client.get(
            f"/api/agent/history/{user_external_id}",
            params={"session_id": "integration_test_session"},
        )
        assert history_response.status_code in [
            200,
            500,
            503,
        ]  # Allow for service failures

        if history_response.status_code == 200:
            history_data = history_response.json()
            assert "history" in history_data
            assert (
                history_data["total_messages"] >= 0
            )  # May be 0 if agent storage not working in test

    @patch("agent.healthcare.conversion.conversion_service.OpenAI")
    def test_error_handling_in_workflow(self, mock_openai):
        """Test error handling throughout the workflow."""

        # Test 1: Invalid file upload
        invalid_response = self.client.post(
            "/api/upload",
            data={"user_external_id": "test_user"},
            files={"file": ("invalid.txt", b"not a pdf", "text/plain")},
        )
        assert invalid_response.status_code in [400, 422]  # Should reject non-PDF

        # Test 2: Missing user ID
        with open(self.sample_pdf_path, "rb") as pdf_file:
            missing_user_response = self.client.post(
                "/api/upload",
                data={},  # Missing user_external_id
                files={"file": ("sample.pdf", pdf_file, "application/pdf")},
            )
        assert missing_user_response.status_code == 422  # Validation error

        # Test 3: Search with invalid user
        search_response = self.client.get(
            "/api/nonexistent_user/search", params={"q": "test query"}
        )
        assert search_response.status_code in [
            200,
            404,
            503,
        ]  # Should handle gracefully or service unavailable

        # Test 4: Agent query with invalid user
        agent_response = self.client.post(
            "/api/agent/chat",
            json={"user_external_id": "nonexistent_user", "query": "test query"},
        )
        # Should not crash - agent will handle gracefully or service unavailable
        assert agent_response.status_code in [200, 400, 404, 500, 503]

    @pytest.mark.skip
    def test_multi_document_workflow(self):
        """Test workflow with multiple documents for the same user."""

        with (
            patch(
                "agent.healthcare.conversion.conversion_service.OpenAI"
            ) as mock_openai,
            patch(
                "agent.healthcare.images.image_service.extract_images_from_pdf"
            ) as mock_extract,
        ):

            # Setup mocks
            mock_openai_client = Mock()
            mock_openai.return_value = mock_openai_client

            mock_file_response = Mock()
            mock_file_response.id = "file-123456"
            mock_openai_client.files.create.return_value = mock_file_response

            # Mock different conversion results for each document
            conversion_results = [
                {
                    "markdown": "# Blood Work Results\n\n## Lab Values\n- Cholesterol: 180 mg/dL\n- Glucose: 95 mg/dL",
                    "manifest": {"figures": [], "tables": []},
                },
                {
                    "markdown": "# Annual Physical\n\n## Vital Signs\n- Blood Pressure: 118/75 mmHg\n- Weight: 170 lbs",
                    "manifest": {"figures": [], "tables": []},
                },
            ]

            mock_extract.return_value = []
            user_external_id = "multi_doc_user"
            report_ids = []

            # Upload multiple documents
            for i, result in enumerate(conversion_results):
                mock_parse_response = Mock()
                mock_parse_response.output_parsed = Mock()
                mock_parse_response.output_parsed.markdown = result["markdown"]
                mock_parse_response.output_parsed.manifest = result["manifest"]
                mock_openai_client.responses.parse.return_value = mock_parse_response

                # Create unique PDF for each upload
                pdf_path = self.test_data_dir / f"report_{i}.pdf"
                pdf_path.write_bytes(self.sample_pdf_path.read_bytes())

                with open(pdf_path, "rb") as pdf_file:
                    upload_response = self.client.post(
                        "/api/upload",
                        data={"user_external_id": user_external_id},
                        files={
                            "file": (f"report_{i}.pdf", pdf_file, "application/pdf")
                        },
                    )

                assert upload_response.status_code == 200
                upload_data = upload_response.json()
                report_ids.append(upload_data["report_id"])

            # Verify both reports are listed
            reports_response = self.client.get(f"/reports/{user_external_id}")
            assert reports_response.status_code in [
                200,
                503,
            ]  # Allow for service unavailable

            if reports_response.status_code == 200:
                reports_data = reports_response.json()
                assert len(reports_data["reports"]) == 2

            # Verify we can search across both documents
            search_response = self.client.get(
                f"/api/{user_external_id}/search",
                params={"q": "cholesterol blood pressure", "k": 10},
            )
            assert search_response.status_code in [
                200,
                503,
            ]  # Allow for service unavailable

            if search_response.status_code == 200:
                search_data = search_response.json()

                # Should find content from both documents
                results_content = " ".join(
                    [r["content"] for r in search_data["results"]]
                )
                # Note: Actual search results depend on embeddings being generated
                # In a real integration test, we would verify cross-document search works

    @pytest.mark.skip
    def test_data_isolation_between_users(self):
        """Test that data is properly isolated between different users."""

        with (
            patch(
                "agent.healthcare.conversion.conversion_service.OpenAI"
            ) as mock_openai,
            patch(
                "agent.healthcare.images.image_service.extract_images_from_pdf"
            ) as mock_extract,
        ):

            # Setup mocks
            mock_openai_client = Mock()
            mock_openai.return_value = mock_openai_client

            mock_file_response = Mock()
            mock_file_response.id = "file-123456"
            mock_openai_client.files.create.return_value = mock_file_response

            mock_parse_response = Mock()
            mock_parse_response.output_parsed = Mock()
            mock_parse_response.output_parsed.markdown = (
                "# User1 Report\n\nPrivate medical data for user1"
            )
            mock_parse_response.output_parsed.manifest = {"figures": [], "tables": []}
            mock_openai_client.responses.parse.return_value = mock_parse_response

            mock_extract.return_value = []

            # Upload document for user1
            with open(self.sample_pdf_path, "rb") as pdf_file:
                user1_upload = self.client.post(
                    "/api/upload",
                    data={"user_external_id": "user1"},
                    files={"file": ("user1_report.pdf", pdf_file, "application/pdf")},
                )

            assert user1_upload.status_code == 200
            user1_report_id = user1_upload.json()["report_id"]

            # Upload document for user2 (with different content)
            mock_parse_response.output_parsed.markdown = (
                "# User2 Report\n\nPrivate medical data for user2"
            )

            with open(self.sample_pdf_path, "rb") as pdf_file:
                user2_upload = self.client.post(
                    "/api/upload",
                    data={"user_external_id": "user2"},
                    files={"file": ("user2_report.pdf", pdf_file, "application/pdf")},
                )

            assert user2_upload.status_code == 200
            user2_report_id = user2_upload.json()["report_id"]

            # Verify user1 can only see their own reports
            user1_reports = self.client.get("/reports/user1")
            assert user1_reports.status_code in [
                200,
                503,
            ]  # Allow for service unavailable

            if user1_reports.status_code == 200:
                user1_data = user1_reports.json()
                assert len(user1_data["reports"]) == 1
                assert user1_data["reports"][0]["id"] == user1_report_id

            # Verify user2 can only see their own reports
            user2_reports = self.client.get("/reports/user2")
            assert user2_reports.status_code in [
                200,
                503,
            ]  # Allow for service unavailable

            if user2_reports.status_code == 200:
                user2_data = user2_reports.json()
                assert len(user2_data["reports"]) == 1
                assert user2_data["reports"][0]["id"] == user2_report_id

            # Verify user1 cannot access user2's report directly
            cross_access_response = self.client.get(
                f"/reports/{user2_report_id}/markdown",
                params={"user_external_id": "user1"},
            )
            assert cross_access_response.status_code in [
                403,
                404,
                503,
            ]  # Should be denied or service unavailable

            # Verify search results are isolated
            user1_search = self.client.get(
                "/api/user1/search", params={"q": "medical data"}
            )
            assert user1_search.status_code in [
                200,
                503,
            ]  # Allow for service unavailable

            user2_search = self.client.get(
                "/api/user2/search", params={"q": "medical data"}
            )
            assert user2_search.status_code in [
                200,
                503,
            ]  # Allow for service unavailable

            # Search results should be different (though content depends on embedding generation)
            if user1_search.status_code == 200 and user2_search.status_code == 200:
                user1_results = user1_search.json()["results"]
                user2_results = user2_search.json()["results"]

                # Basic verification that searches return results for respective users
                # (Exact content verification would require real embeddings)
                assert isinstance(user1_results, list)
                assert isinstance(user2_results, list)
